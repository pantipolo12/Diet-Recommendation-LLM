{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pantipolo12/Diet-Recommendation-LLM/blob/main/Diet_Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCR (Optical Character Recognition)"
      ],
      "metadata": {
        "id": "YsJj-odvNP4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Given Dataset (Chose relevant prescriptions)\n",
        "!gdown 1DvcXqFzEDlrFQTOQV_qEZjDWBT1MnnFl\n",
        "!gdown 1ENdiOHRYL8ImpFuBR9nLSRohF8nBmvJS\n",
        "!gdown 1rHIa19GiUb5xlG6ptdJXyaTs5GD8tyl0\n",
        "!gdown 196Ww4pmzDvRHNIhBU4zhwfO9cY7qQJI0"
      ],
      "metadata": {
        "id": "wPc5e-VB3Be7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pERmOcNmr71w"
      },
      "outputs": [],
      "source": [
        "# Installing OCR libraries\n",
        "%%capture\n",
        "!pip install pypdfium2\n",
        "!pip install poppler-utils\n",
        "!pip install pdf2image\n",
        "!pip install tesseract-ocr\n",
        "!pip install libtesseract-dev\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pypdfium2 as pyp\n",
        "from pdf2image import convert_from_path\n",
        "from IPython.display import display, Image\n",
        "import cv2\n",
        "import pytesseract\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "tAcE527ksV92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removes any skew in the image\n",
        "def deskew(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.bitwise_not(gray)\n",
        "    coords = np.column_stack(np.where(gray > 0))\n",
        "    angle = cv2.minAreaRect(coords)[-1]\n",
        "\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = -angle\n",
        "\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "    return rotated\n",
        "\n",
        "# Extracts text from image\n",
        "def extract_text_from_image(image):\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text"
      ],
      "metadata": {
        "id": "XBV6aemu4Tel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the pdfs are stored\n",
        "data_dir = '/content'"
      ],
      "metadata": {
        "id": "QJvchPOO4UB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns tokenized text extracted from pdf or images after new line/empty string removal\n",
        "def read_prescription(path):\n",
        "  pdf = pyp.PdfDocument(path)\n",
        "  pages = len(pdf)\n",
        "  text = []\n",
        "\n",
        "  for i in range(pages):\n",
        "      raw = pdf[i].get_textpage().get_text_range()\n",
        "      words = word_tokenize(raw)\n",
        "      text.extend(words)\n",
        "\n",
        "  # If the pdf is not read, that means we have an image and we read via OCR\n",
        "  if len(text) == 0:\n",
        "    pages = convert_from_path(path)\n",
        "    extracted_text = []\n",
        "\n",
        "    for page in pages:\n",
        "        preprocessed_image = deskew(np.array(page))\n",
        "        text1 = extract_text_from_image(preprocessed_image)\n",
        "        extracted_text.append(text1)\n",
        "\n",
        "    # The text extracted is erronous, we combine all of it and then split\n",
        "    # via spaces and remove unnecessary new line characters and empty strings\n",
        "    text.extend(extracted_text)\n",
        "    temp = \"\"\n",
        "    for x in text:\n",
        "      temp += x + \" \"\n",
        "    text = [temp]\n",
        "\n",
        "    text = text[0].split(\" \")\n",
        "    remove = []\n",
        "    for i in range(len(text)):\n",
        "      text[i] = re.sub('\\n', '', text[i])\n",
        "      if text[i] == \"\":\n",
        "        remove.append(i)\n",
        "    for i in remove[::-1]:\n",
        "      text.pop(i)\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "NCnVZPBX4dqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all the pdf files in the current directory\n",
        "pdf_files = [f for f in os.listdir(data_dir) if f.endswith('.pdf')]\n",
        "\n",
        "# Empty df\n",
        "df = pd.DataFrame(columns=['file', 'text'])\n",
        "title = []\n",
        "texts = []\n",
        "for pdf_file in pdf_files:\n",
        "  path = os.path.join(data_dir, pdf_file)\n",
        "  text = read_prescription(path)\n",
        "  texts.append(text)\n",
        "  title.append(pdf_file)\n",
        "\n",
        "df['file'] = title\n",
        "df['text'] = texts"
      ],
      "metadata": {
        "id": "3qCtxCzt4Vs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting medications or advice\n",
        "keywords = [\"medication\", \"medicine\", \"advice\", \"advised\" , \"food\", \"diet\", \"meal\"]\n",
        "medicines = []\n",
        "for i in range(df.shape[0]):\n",
        "  prescription = df.iloc[i][1]\n",
        "  flag = False\n",
        "  for word in keywords:\n",
        "    for med in range(len(prescription)):\n",
        "      if word in prescription[med].lower():\n",
        "        prescription = prescription[med:]\n",
        "        flag = True\n",
        "      if flag:\n",
        "        break\n",
        "    if flag:\n",
        "      break\n",
        "  medicines.append(\" \".join(prescription))\n",
        "\n",
        "df[\"extracted\"] = medicines"
      ],
      "metadata": {
        "id": "kOSeQ80JEKAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete = []\n",
        "for i in range(df.shape[0]):\n",
        "  prescription = df.iloc[i][1]\n",
        "  prescription = \" \".join(prescription)\n",
        "  complete.append(prescription)\n",
        "\n",
        "df[\"complete\"] = complete"
      ],
      "metadata": {
        "id": "Kdy3cSp9Y0DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "7eVmHJazZF5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[1][2]"
      ],
      "metadata": {
        "id": "KU5ek2Z4Eui5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini (A Generative AI Model developed by Google)"
      ],
      "metadata": {
        "id": "9FZMb6bQNNLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install google-generativeai"
      ],
      "metadata": {
        "id": "m49jvNuxJ2XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gemini API: {YOUR_API_KEY_HERE}\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_key = userdata.get('secret')\n",
        "\n",
        "# Configure google-generativeai library with the API key\n",
        "genai.configure(api_key = gemini_key)"
      ],
      "metadata": {
        "id": "z_5_MaN1JilU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supported models for generateContent method\n",
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "id": "1WXN0osZKMad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Test for Gemini\n",
        "from IPython.display import Markdown\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "response = model.generate_content(\"Can you provide medical details of say DOLO tablets.\")\n",
        "\n",
        "Markdown(response.text) #display text as Markdown"
      ],
      "metadata": {
        "id": "3cjVaaMDKVg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prescription Test for Gemini\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "for i in range(df.shape[0]):\n",
        "\n",
        "  print(f\"Below Prescription: {df.iloc[i][0]}\")\n",
        "\n",
        "  response = model.generate_content(df.iloc[i][2] + \". Please identify medicines and their associated symptoms from this prescription, also identify associated diseases. Based on this give Food Recommendations.\")\n",
        "\n",
        "  display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "IwaoGS-VLIP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prescription Test for Gemini\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "for i in range(df.shape[0]):\n",
        "\n",
        "  print(f\"Below Prescription: {df.iloc[i][0]}\")\n",
        "\n",
        "  response = model.generate_content(df.iloc[i][3] + \". Please identify medicines and their associated symptoms from this prescription, also identify associated diseases.  Based on this give Food Recommendations. Structure response in simple table format\")\n",
        "\n",
        "  display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "NdMfXdr6ZK--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.candidates[0].content.parts[0].text"
      ],
      "metadata": {
        "id": "fNLhIDPXM6RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gemini_prompt(prompt):\n",
        "  import os\n",
        "  import google.generativeai as genai\n",
        "  from google.colab import userdata\n",
        "\n",
        "  gemini_key = userdata.get('secret')\n",
        "\n",
        "  # Configure google-generativeai library with the API key\n",
        "\n",
        "  genai.configure(api_key = gemini_key)\n",
        "  model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "  response = model.generate_content(prompt)\n",
        "  return response"
      ],
      "metadata": {
        "id": "uHyKUyJ_O6m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama (Large Language Model Meta AI)"
      ],
      "metadata": {
        "id": "avpPGZk4WMid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-generativeai -q\n",
        "\n",
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Use your Google AI Studio key\n",
        "genai.configure(api_key=\"secret\")\n"
      ],
      "metadata": {
        "id": "o8Ts5I9dWN1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y google-generativeai google-ai-generativelanguage\n",
        "!pip install -U google-generativeai\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhL5s8agvflG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Configure Gemini (replace with your API key or Colab userdata)\n",
        "gen_key = userdata.get('secret')\n",
        "genai.configure(api_key=gen_key)\n",
        "\n",
        "def run_gemini(api_request_json):\n",
        "    # Force correct Gemini model (v1 style)\n",
        "    model_name = api_request_json.get(\"model\", \"gemini-2.5-flash\")\n",
        "    if not model_name.startswith(\"gemini\"):\n",
        "        model_name = \"gemini-2.5-flash\"\n",
        "\n",
        "    messages = api_request_json[\"messages\"]\n",
        "\n",
        "    # Build prompt\n",
        "    system_prompt = \"\"\n",
        "    conversation = \"\"\n",
        "    for msg in messages:\n",
        "        if msg[\"role\"] == \"system\":\n",
        "            system_prompt += msg[\"content\"] + \"\\n\"\n",
        "        elif msg[\"role\"] == \"user\":\n",
        "            conversation += f\"User: {msg['content']}\\n\"\n",
        "\n",
        "    prompt = system_prompt + \"\\n\" + conversation\n",
        "\n",
        "    # Use v1 API\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return {\"choices\": [{\"message\": {\"content\": response.text}}]}\n",
        "\n",
        "\n",
        "# ✅ Test call\n",
        "api_request_json = {\n",
        "    \"model\": \"llama3-70b\",  # automatically replaced\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"You are a llama assistant that starts every word with 'll'.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hi, happy llama day!\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "response = run_gemini(api_request_json)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "id": "PcDParv10Qzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_gemini(api_request_json)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "h1InzqOdxkDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Prescription test using Gemini (replaces llama.run)\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Build API-style request (same as before)\n",
        "api_request_json = {\n",
        "  \"model\": \"gemini-2.5-flash\",  # replaced llama3-70b with Gemini model\n",
        "  \"messages\": [\n",
        "    {\"role\": \"system\", \"content\": \"Please provide information about different medicines, their symptoms and their associated diseases from the prescription.\"},\n",
        "    {\"role\": \"user\", \"content\": df.iloc[0][2]},\n",
        "    {\"role\": \"user\", \"content\": df.iloc[1][2]},\n",
        "    {\"role\": \"user\", \"content\": df.iloc[2][2]},\n",
        "    {\"role\": \"user\", \"content\": df.iloc[3][2]}\n",
        "  ]\n",
        "}\n",
        "\n",
        "# Run with Gemini wrapper\n",
        "response = run_gemini(api_request_json)\n",
        "\n",
        "# Extract model output\n",
        "gemini_output = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# Display nicely\n",
        "display(Markdown(gemini_output))\n"
      ],
      "metadata": {
        "id": "sFPYW85MWdnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy and Validity Check for Prescriptions\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "for i in range(df.shape[0]):\n",
        "    prescription_text = df.iloc[i][3]  # complete text\n",
        "    prompt = f\"\"\"\n",
        "    Evaluate the following prescription analysis for accuracy and validity.\n",
        "    Prescription: {prescription_text}\n",
        "\n",
        "    Please provide:\n",
        "    1. A validity percentage (how complete and correct is the extracted medicine/disease/food info).\n",
        "    2. An error percentage (how much information is missing or incorrect).\n",
        "    3. Overall accuracy estimate (based on medical correctness and completeness).\n",
        "    Provide the results as a simple table:\n",
        "    | Validity (%) | Error (%) | Accuracy (%) |\n",
        "    \"\"\"\n",
        "    response = gemini_prompt(prompt)\n",
        "    print(f\"Prescription: {df.iloc[i][0]}\")\n",
        "    display(Markdown(response.text))\n"
      ],
      "metadata": {
        "id": "AA13pmGTZtnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Pipeline"
      ],
      "metadata": {
        "id": "g_mBCv_fPLiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "id": "PQ3aWsE6vKwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!which pdfinfo\n",
        "!which pdftoppm"
      ],
      "metadata": {
        "id": "J7mLSBN0vZM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_diet_recommendation():\n",
        "    from google.colab import files\n",
        "    from pdf2image import convert_from_path\n",
        "    from IPython.display import Image, Markdown, display\n",
        "\n",
        "    # Ask the user to upload a file\n",
        "    print(\"Please upload a PDF prescription file:\")\n",
        "    uploaded_file = files.upload()\n",
        "\n",
        "    # Check if a file was uploaded\n",
        "    if len(uploaded_file) > 0:\n",
        "        file_name = next(iter(uploaded_file))\n",
        "        if not file_name.endswith(\".pdf\"):\n",
        "            print(\"The uploaded file is not a PDF.\")\n",
        "            return\n",
        "        print(\"File uploaded successfully:\", file_name)\n",
        "    else:\n",
        "        print(\"No file uploaded.\")\n",
        "        return\n",
        "\n",
        "    # Convert first page of PDF to image and display it\n",
        "    file_path = \"/content/\" + file_name\n",
        "    pages = convert_from_path(file_path, poppler_path=\"/usr/bin\", first_page=1, last_page=1)\n",
        "    first_page_image = pages[0]\n",
        "    image_path = \"/content/first_page_image.png\"\n",
        "    first_page_image.save(image_path, \"PNG\")\n",
        "\n",
        "    print(\"\\nDisplaying first page of the uploaded PDF:\")\n",
        "    display(Image(filename=image_path, width=600))\n",
        "\n",
        "    # Step 1 — OCR the uploaded PDF\n",
        "    print(\"\\nReading Text...\")\n",
        "    ocr = read_prescription(file_path)\n",
        "    ocr_text = \" \".join(ocr)\n",
        "\n",
        "    # Step 2 — Build request for Gemini\n",
        "    print(\"\\nIdentifying diseases and medicines...\")\n",
        "    api_request_json = {\n",
        "        \"model\": \"gemini-2.5-flash\",  # updated model name\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": (\n",
        "                \"You are a medical analysis assistant. \"\n",
        "                \"Extract medicines from the uploaded prescription, identify their associated symptoms \"\n",
        "                \"and diseases, and provide food recommendations in a clear table format.\"\n",
        "            )},\n",
        "            {\"role\": \"user\", \"content\": ocr_text}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Step 3 — Run Gemini request\n",
        "    response = run_gemini(api_request_json)\n",
        "    gemini_output = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    # Step 4 — Display results\n",
        "    print(\"\\nGenerating diet recommendations...\")\n",
        "    display(Markdown(gemini_output))\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "CznlhDgcPK5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_diet_recommendation()"
      ],
      "metadata": {
        "id": "pL_tx2aoQdSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_diet_recommendation()\n"
      ],
      "metadata": {
        "id": "WuFwngOFyd6G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}